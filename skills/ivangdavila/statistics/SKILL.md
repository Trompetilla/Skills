---
name: Statistics
description: Build statistical intuition from basic probability to advanced inference.
metadata: {"clawdbot":{"emoji":"ðŸ“Š","os":["linux","darwin","win32"]}}
---

## Detect Level, Adapt Everything
- Context reveals level: notation familiarity, software mentioned, problem complexity
- When unclear, start with concrete examples and adjust based on response
- Never condescend to experts or overwhelm beginners

## For Beginners: Intuition Before Formulas
- Probability through physical objects â€” dice, coins, cards, colored balls in bags
- Averages as balance points â€” "If everyone shared equally, each would get..."
- Variation matters as much as center â€” two classes with same average, very different spreads
- Graphs before numbers â€” show the shape, then quantify it
- Sampling as tasting soup â€” one spoonful tells you about the pot if well stirred
- Correlation isn't causation â€” ice cream sales and drowning both rise in summer
- Connect to their decisions â€” weather forecasts, medical tests, sports statistics

## For Students: Frameworks and Assumptions
- Name the test AND its assumptions â€” normality, independence, equal variance
- Effect size alongside p-value â€” statistical significance â‰  practical importance
- Confidence intervals tell richer stories than hypothesis tests alone
- Distinguish population parameters from sample statistics â€” Greek vs Roman letters matter
- Simulation builds intuition â€” bootstrap, permutation tests show what formulas hide
- Regression diagnostics before interpretation â€” residual plots catch violations
- Bayesian vs frequentist â€” acknowledge the philosophical divide, explain context for each

## For Researchers: Rigor and Honesty
- Pre-registration prevents p-hacking â€” specify analysis before seeing data
- Power analysis before collecting â€” underpowered studies waste resources
- Multiple comparisons require adjustment â€” Bonferroni, FDR, or justify why not
- Report effect sizes and confidence intervals â€” not just p-values
- Missing data mechanisms matter â€” MCAR, MAR, MNAR require different treatments
- Causal inference needs design â€” DAGs, potential outcomes, state assumptions explicitly
- Reproducibility means code and data â€” "available upon request" is not reproducible

## For Teachers: Common Misconceptions
- p-value is NOT probability hypothesis is true â€” it's probability of data given null
- Failing to reject â‰  accepting null â€” absence of evidence isn't evidence of absence
- Large samples don't fix bias â€” garbage in, garbage out regardless of n
- Standard deviation vs standard error â€” population spread vs sampling precision
- Correlation coefficient hides nonlinearity â€” always plot first
- Use real messy data â€” textbook examples with clean answers mislead
- Teach skepticism â€” "How was this measured? Who was sampled? What's missing?"

## Always
- Visualize data before computing anything
- State assumptions explicitly â€” every test has them
- Distinguish exploratory from confirmatory â€” same data can't do both
